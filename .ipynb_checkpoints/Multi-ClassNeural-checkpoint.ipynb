{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.96014042  -1.57613039  -1.54298157 ...  -4.3201575  -20.04180908\n",
      "   -1.92534327]\n",
      " [ -1.6680493   -1.60666069  -1.55044537 ...  -3.26517849 -15.20510111\n",
      "   -1.91514305]\n",
      " [ -1.43207967  -1.60666069  -1.55059465 ...  -0.10024147  -7.46636838\n",
      "   -1.86519525]\n",
      " ...\n",
      " [ -2.061332    -1.69882762  -1.57441912 ...  -6.43011551   9.94578029\n",
      "   -1.85499503]\n",
      " [ -1.82536238  -1.69479532  -1.57310549 ...  -6.43011551   5.10907232\n",
      "   -1.89696006]\n",
      " [ -2.13998854  -1.68845884  -1.57110519 ... -14.86994758  -8.43370997\n",
      "   -1.96680937]]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"DONNES/train_cap2018.csv\")\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,1:58].astype(float)\n",
    "Y = dataset[:,59]\n",
    "\n",
    "where_are_NaNs = numpy.isnan(X) #Remplace les valeurs NaN par des 0\n",
    "X[where_are_NaNs] = 0\n",
    "\n",
    "print(X)\n",
    "#Normalisation \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X = scaler.transform(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "#print(X)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "#print(encoded_Y)\n",
    "#list(encoder.inverse_transform(encoded_Y)) la d√©marche inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(10, input_dim=57,kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(10, activation='relu'))\n",
    "\tmodel.add(Dense(6, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "27310/27310 [==============================] - 4s 133us/step - loss: 0.9571 - acc: 0.6234\n",
      "Epoch 2/150\n",
      "27310/27310 [==============================] - 3s 102us/step - loss: 0.7871 - acc: 0.6943\n",
      "Epoch 3/150\n",
      "27310/27310 [==============================] - 3s 112us/step - loss: 0.7735 - acc: 0.6999\n",
      "Epoch 4/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7694 - acc: 0.6999 0s - loss: 0.7693 - acc: 0.6\n",
      "Epoch 5/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7639 - acc: 0.7029\n",
      "Epoch 6/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7615 - acc: 0.7046\n",
      "Epoch 7/150\n",
      "27310/27310 [==============================] - 4s 151us/step - loss: 0.7607 - acc: 0.7013\n",
      "Epoch 8/150\n",
      "27310/27310 [==============================] - 5s 166us/step - loss: 0.7576 - acc: 0.7023\n",
      "Epoch 9/150\n",
      "27310/27310 [==============================] - 5s 166us/step - loss: 0.7553 - acc: 0.7048\n",
      "Epoch 10/150\n",
      "27310/27310 [==============================] - 4s 160us/step - loss: 0.7535 - acc: 0.7068\n",
      "Epoch 11/150\n",
      "27310/27310 [==============================] - 5s 171us/step - loss: 0.7526 - acc: 0.7059\n",
      "Epoch 12/150\n",
      "27310/27310 [==============================] - 4s 163us/step - loss: 0.7509 - acc: 0.7054\n",
      "Epoch 13/150\n",
      "27310/27310 [==============================] - 5s 183us/step - loss: 0.7495 - acc: 0.7077\n",
      "Epoch 14/150\n",
      "27310/27310 [==============================] - 4s 133us/step - loss: 0.7479 - acc: 0.7067\n",
      "Epoch 15/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7488 - acc: 0.7049\n",
      "Epoch 16/150\n",
      "27310/27310 [==============================] - 4s 159us/step - loss: 0.7473 - acc: 0.7091\n",
      "Epoch 17/150\n",
      "27310/27310 [==============================] - 4s 136us/step - loss: 0.7475 - acc: 0.7090\n",
      "Epoch 18/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7461 - acc: 0.7074\n",
      "Epoch 19/150\n",
      "27310/27310 [==============================] - 4s 134us/step - loss: 0.7435 - acc: 0.7098\n",
      "Epoch 20/150\n",
      "27310/27310 [==============================] - 3s 126us/step - loss: 0.7445 - acc: 0.7089\n",
      "Epoch 21/150\n",
      "27310/27310 [==============================] - 3s 120us/step - loss: 0.7424 - acc: 0.7105\n",
      "Epoch 22/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7422 - acc: 0.7093\n",
      "Epoch 23/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7407 - acc: 0.7085\n",
      "Epoch 24/150\n",
      "27310/27310 [==============================] - 3s 98us/step - loss: 0.7413 - acc: 0.7125\n",
      "Epoch 25/150\n",
      "27310/27310 [==============================] - 3s 95us/step - loss: 0.7420 - acc: 0.7081\n",
      "Epoch 26/150\n",
      "27310/27310 [==============================] - 3s 93us/step - loss: 0.7410 - acc: 0.7101\n",
      "Epoch 27/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7403 - acc: 0.7104 0s - loss: 0.740\n",
      "Epoch 28/150\n",
      "27310/27310 [==============================] - 4s 128us/step - loss: 0.7399 - acc: 0.7105\n",
      "Epoch 29/150\n",
      "27310/27310 [==============================] - 3s 128us/step - loss: 0.7395 - acc: 0.7097\n",
      "Epoch 30/150\n",
      "27310/27310 [==============================] - 4s 149us/step - loss: 0.7389 - acc: 0.7104\n",
      "Epoch 31/150\n",
      "27310/27310 [==============================] - 3s 125us/step - loss: 0.7374 - acc: 0.7114\n",
      "Epoch 32/150\n",
      "27310/27310 [==============================] - 3s 120us/step - loss: 0.7381 - acc: 0.7091\n",
      "Epoch 33/150\n",
      "27310/27310 [==============================] - 3s 123us/step - loss: 0.7373 - acc: 0.7118\n",
      "Epoch 34/150\n",
      "27310/27310 [==============================] - 4s 133us/step - loss: 0.7373 - acc: 0.7112\n",
      "Epoch 35/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7366 - acc: 0.7111\n",
      "Epoch 36/150\n",
      "27310/27310 [==============================] - 3s 102us/step - loss: 0.7350 - acc: 0.7126\n",
      "Epoch 37/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7356 - acc: 0.7116\n",
      "Epoch 38/150\n",
      "27310/27310 [==============================] - 3s 118us/step - loss: 0.7362 - acc: 0.7120\n",
      "Epoch 39/150\n",
      "27310/27310 [==============================] - 3s 123us/step - loss: 0.7362 - acc: 0.7125\n",
      "Epoch 40/150\n",
      "27310/27310 [==============================] - 3s 124us/step - loss: 0.7358 - acc: 0.7118\n",
      "Epoch 41/150\n",
      "27310/27310 [==============================] - 3s 125us/step - loss: 0.7355 - acc: 0.7107\n",
      "Epoch 42/150\n",
      "27310/27310 [==============================] - 3s 125us/step - loss: 0.7345 - acc: 0.7121\n",
      "Epoch 43/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7344 - acc: 0.7131\n",
      "Epoch 44/150\n",
      "27310/27310 [==============================] - 3s 104us/step - loss: 0.7340 - acc: 0.7127\n",
      "Epoch 45/150\n",
      "27310/27310 [==============================] - 3s 104us/step - loss: 0.7332 - acc: 0.7137\n",
      "Epoch 46/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7331 - acc: 0.7137\n",
      "Epoch 47/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7322 - acc: 0.7130\n",
      "Epoch 48/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7322 - acc: 0.7130\n",
      "Epoch 49/150\n",
      "27310/27310 [==============================] - 3s 120us/step - loss: 0.7320 - acc: 0.7128\n",
      "Epoch 50/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7317 - acc: 0.7123\n",
      "Epoch 51/150\n",
      "27310/27310 [==============================] - 3s 123us/step - loss: 0.7322 - acc: 0.7133\n",
      "Epoch 52/150\n",
      "27310/27310 [==============================] - 3s 118us/step - loss: 0.7315 - acc: 0.7165\n",
      "Epoch 53/150\n",
      "27310/27310 [==============================] - 3s 121us/step - loss: 0.7311 - acc: 0.7137\n",
      "Epoch 54/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7304 - acc: 0.7148\n",
      "Epoch 55/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7312 - acc: 0.7155\n",
      "Epoch 56/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7303 - acc: 0.7145 1\n",
      "Epoch 57/150\n",
      "27310/27310 [==============================] - 3s 118us/step - loss: 0.7294 - acc: 0.7149\n",
      "Epoch 58/150\n",
      "27310/27310 [==============================] - 3s 114us/step - loss: 0.7280 - acc: 0.7142\n",
      "Epoch 59/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7287 - acc: 0.7130\n",
      "Epoch 60/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7291 - acc: 0.7148\n",
      "Epoch 61/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7295 - acc: 0.7144\n",
      "Epoch 62/150\n",
      "27310/27310 [==============================] - 3s 104us/step - loss: 0.7289 - acc: 0.7136\n",
      "Epoch 63/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7275 - acc: 0.7171\n",
      "Epoch 64/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7276 - acc: 0.7160\n",
      "Epoch 65/150\n",
      "27310/27310 [==============================] - 3s 112us/step - loss: 0.7277 - acc: 0.7157\n",
      "Epoch 66/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7291 - acc: 0.7136\n",
      "Epoch 67/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7275 - acc: 0.7148\n",
      "Epoch 68/150\n",
      "27310/27310 [==============================] - 3s 114us/step - loss: 0.7272 - acc: 0.7145\n",
      "Epoch 69/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7260 - acc: 0.7163\n",
      "Epoch 70/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7269 - acc: 0.7169\n",
      "Epoch 71/150\n",
      "27310/27310 [==============================] - 3s 107us/step - loss: 0.7263 - acc: 0.7167\n",
      "Epoch 72/150\n",
      "27310/27310 [==============================] - 3s 124us/step - loss: 0.7251 - acc: 0.7154\n",
      "Epoch 73/150\n",
      "27310/27310 [==============================] - 4s 129us/step - loss: 0.7259 - acc: 0.7141\n",
      "Epoch 74/150\n",
      "27310/27310 [==============================] - 4s 130us/step - loss: 0.7243 - acc: 0.7159\n",
      "Epoch 75/150\n",
      "27310/27310 [==============================] - 3s 120us/step - loss: 0.7268 - acc: 0.7155\n",
      "Epoch 76/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7255 - acc: 0.7148\n",
      "Epoch 77/150\n",
      "27310/27310 [==============================] - 3s 109us/step - loss: 0.7232 - acc: 0.7178\n",
      "Epoch 78/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7247 - acc: 0.7139\n",
      "Epoch 79/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7237 - acc: 0.7150\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27310/27310 [==============================] - 3s 118us/step - loss: 0.7240 - acc: 0.7168\n",
      "Epoch 81/150\n",
      "27310/27310 [==============================] - 3s 111us/step - loss: 0.7236 - acc: 0.7164 0s - loss: 0.726\n",
      "Epoch 82/150\n",
      "27310/27310 [==============================] - 3s 102us/step - loss: 0.7225 - acc: 0.7178\n",
      "Epoch 83/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7239 - acc: 0.7168\n",
      "Epoch 84/150\n",
      "27310/27310 [==============================] - 3s 107us/step - loss: 0.7225 - acc: 0.7167\n",
      "Epoch 85/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7223 - acc: 0.7185\n",
      "Epoch 86/150\n",
      "27310/27310 [==============================] - 3s 108us/step - loss: 0.7219 - acc: 0.7161\n",
      "Epoch 87/150\n",
      "27310/27310 [==============================] - 3s 95us/step - loss: 0.7220 - acc: 0.7175\n",
      "Epoch 88/150\n",
      "27310/27310 [==============================] - 3s 96us/step - loss: 0.7231 - acc: 0.7163\n",
      "Epoch 89/150\n",
      "27310/27310 [==============================] - 3s 97us/step - loss: 0.7211 - acc: 0.7163\n",
      "Epoch 90/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7213 - acc: 0.7168\n",
      "Epoch 91/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7217 - acc: 0.7170\n",
      "Epoch 92/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7202 - acc: 0.7186 0s - loss: 0.7235\n",
      "Epoch 93/150\n",
      "27310/27310 [==============================] - 4s 143us/step - loss: 0.7204 - acc: 0.7176\n",
      "Epoch 94/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7214 - acc: 0.7179\n",
      "Epoch 95/150\n",
      "27310/27310 [==============================] - 3s 118us/step - loss: 0.7221 - acc: 0.7175\n",
      "Epoch 96/150\n",
      "27310/27310 [==============================] - 3s 98us/step - loss: 0.7214 - acc: 0.7176\n",
      "Epoch 97/150\n",
      "27310/27310 [==============================] - 3s 101us/step - loss: 0.7193 - acc: 0.7166\n",
      "Epoch 98/150\n",
      "27310/27310 [==============================] - 3s 100us/step - loss: 0.7199 - acc: 0.7179\n",
      "Epoch 99/150\n",
      "27310/27310 [==============================] - 3s 101us/step - loss: 0.7196 - acc: 0.7187\n",
      "Epoch 100/150\n",
      "27310/27310 [==============================] - 3s 127us/step - loss: 0.7203 - acc: 0.7176\n",
      "Epoch 101/150\n",
      "27310/27310 [==============================] - 3s 124us/step - loss: 0.7198 - acc: 0.7163\n",
      "Epoch 102/150\n",
      "27310/27310 [==============================] - 3s 122us/step - loss: 0.7195 - acc: 0.7173\n",
      "Epoch 103/150\n",
      "27310/27310 [==============================] - 3s 123us/step - loss: 0.7199 - acc: 0.7164\n",
      "Epoch 104/150\n",
      "27310/27310 [==============================] - 3s 121us/step - loss: 0.7203 - acc: 0.7178\n",
      "Epoch 105/150\n",
      "27310/27310 [==============================] - 3s 127us/step - loss: 0.7187 - acc: 0.7187\n",
      "Epoch 106/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7185 - acc: 0.7160\n",
      "Epoch 107/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7182 - acc: 0.7183\n",
      "Epoch 108/150\n",
      "27310/27310 [==============================] - 3s 102us/step - loss: 0.7185 - acc: 0.7192\n",
      "Epoch 109/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7182 - acc: 0.7194\n",
      "Epoch 110/150\n",
      "27310/27310 [==============================] - 3s 126us/step - loss: 0.7203 - acc: 0.7174\n",
      "Epoch 111/150\n",
      "27310/27310 [==============================] - 3s 124us/step - loss: 0.7176 - acc: 0.7180\n",
      "Epoch 112/150\n",
      "27310/27310 [==============================] - 4s 128us/step - loss: 0.7185 - acc: 0.7196\n",
      "Epoch 113/150\n",
      "27310/27310 [==============================] - 3s 102us/step - loss: 0.7191 - acc: 0.7199\n",
      "Epoch 114/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7194 - acc: 0.7157\n",
      "Epoch 115/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7190 - acc: 0.7171\n",
      "Epoch 116/150\n",
      "27310/27310 [==============================] - 3s 127us/step - loss: 0.7195 - acc: 0.7176\n",
      "Epoch 117/150\n",
      "27310/27310 [==============================] - 3s 123us/step - loss: 0.7180 - acc: 0.7182\n",
      "Epoch 118/150\n",
      "27310/27310 [==============================] - 4s 132us/step - loss: 0.7162 - acc: 0.7201\n",
      "Epoch 119/150\n",
      "27310/27310 [==============================] - 3s 123us/step - loss: 0.7169 - acc: 0.7195\n",
      "Epoch 120/150\n",
      "27310/27310 [==============================] - 3s 122us/step - loss: 0.7181 - acc: 0.7184\n",
      "Epoch 121/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7162 - acc: 0.7187 0s - loss: 0.7\n",
      "Epoch 122/150\n",
      "27310/27310 [==============================] - 3s 104us/step - loss: 0.7159 - acc: 0.7194 0s - loss: 0.7163 - acc: 0.7\n",
      "Epoch 123/150\n",
      "27310/27310 [==============================] - 3s 101us/step - loss: 0.7182 - acc: 0.7188 1s - los\n",
      "Epoch 124/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7181 - acc: 0.7192\n",
      "Epoch 125/150\n",
      "27310/27310 [==============================] - 3s 118us/step - loss: 0.7182 - acc: 0.7166\n",
      "Epoch 126/150\n",
      "27310/27310 [==============================] - 3s 121us/step - loss: 0.7160 - acc: 0.7189\n",
      "Epoch 127/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7188 - acc: 0.7166\n",
      "Epoch 128/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7165 - acc: 0.7188\n",
      "Epoch 129/150\n",
      "27310/27310 [==============================] - 3s 120us/step - loss: 0.7163 - acc: 0.7190\n",
      "Epoch 130/150\n",
      "27310/27310 [==============================] - 3s 118us/step - loss: 0.7152 - acc: 0.7186\n",
      "Epoch 131/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7155 - acc: 0.7211\n",
      "Epoch 132/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7161 - acc: 0.7200\n",
      "Epoch 133/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7168 - acc: 0.7197\n",
      "Epoch 134/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7160 - acc: 0.7181\n",
      "Epoch 135/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7178 - acc: 0.7197\n",
      "Epoch 136/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7149 - acc: 0.7202\n",
      "Epoch 137/150\n",
      "27310/27310 [==============================] - 4s 143us/step - loss: 0.7157 - acc: 0.7192\n",
      "Epoch 138/150\n",
      "27310/27310 [==============================] - 3s 107us/step - loss: 0.7147 - acc: 0.7198\n",
      "Epoch 139/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7157 - acc: 0.7179\n",
      "Epoch 140/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7162 - acc: 0.7182\n",
      "Epoch 141/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7168 - acc: 0.7177\n",
      "Epoch 142/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7149 - acc: 0.7201\n",
      "Epoch 143/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7156 - acc: 0.7189\n",
      "Epoch 144/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7159 - acc: 0.7175\n",
      "Epoch 145/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7145 - acc: 0.7201\n",
      "Epoch 146/150\n",
      "27310/27310 [==============================] - 3s 112us/step - loss: 0.7140 - acc: 0.7189\n",
      "Epoch 147/150\n",
      "27310/27310 [==============================] - 3s 113us/step - loss: 0.7160 - acc: 0.7211\n",
      "Epoch 148/150\n",
      "27310/27310 [==============================] - 3s 108us/step - loss: 0.7155 - acc: 0.7202\n",
      "Epoch 149/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7151 - acc: 0.7196\n",
      "Epoch 150/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7168 - acc: 0.7181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe1d059d30>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(X, dummy_y, epochs=150, batch_size=32) #Attention aux param√®tres, certains changement provoquent l'overfitting !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27310/27310 [==============================] - 2s 55us/step\n",
      "\n",
      "acc: 73.64%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, dummy_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B2' 'B2' 'B2' ... 'A1' 'A1' 'A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#predictions = model.predict(X)\n",
    "predictions = model.predict_classes(X)\n",
    "classes = encoder.inverse_transform(predictions)\n",
    "\n",
    "print(classes)\n",
    "# round predictions\n",
    "#for x in predictions :\n",
    "#    print(x)\n",
    "#print(dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(type(classes))\n",
    "sns.countplot(classes,label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

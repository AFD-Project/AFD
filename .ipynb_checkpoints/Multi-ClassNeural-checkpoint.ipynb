{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"DONNES/train_cap2018.csv\")\n",
    "dataset = dataframe.values\n",
    "\n",
    "X = dataframe.iloc[:,1:59]\n",
    "Y = dataframe.iloc[:,59]\n",
    "\n",
    "X, X_test, Y, y_test = train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "where_are_NaNs = numpy.isnan(X) #Remplace les valeurs NaN par des 0\n",
    "X[where_are_NaNs] = 0\n",
    "\n",
    "where_are_NaNs = numpy.isnan(X_test) #Remplace les valeurs NaN par des 0\n",
    "X_test[where_are_NaNs] = 0\n",
    "\n",
    "#print(X)\n",
    "\n",
    "#Normalisation \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#print(X)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "#print(encoded_Y)\n",
    "#list(encoder.inverse_transform(encoded_Y)) la démarche inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(100, input_dim=58, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(500, activation='relu'))\n",
    "\tmodel.add(Dense(6, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16386/16386 [==============================] - 1s 49us/step - loss: 0.7304 - acc: 0.7160\n",
      "Epoch 2/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.5981 - acc: 0.7708\n",
      "Epoch 3/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.5621 - acc: 0.7853\n",
      "Epoch 4/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.5352 - acc: 0.7935\n",
      "Epoch 5/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.5133 - acc: 0.8004\n",
      "Epoch 6/100\n",
      "16386/16386 [==============================] - 1s 39us/step - loss: 0.4991 - acc: 0.8084\n",
      "Epoch 7/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.4843 - acc: 0.8158\n",
      "Epoch 8/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.4716 - acc: 0.8216\n",
      "Epoch 9/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.4614 - acc: 0.8202\n",
      "Epoch 10/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.4521 - acc: 0.8289\n",
      "Epoch 11/100\n",
      "16386/16386 [==============================] - 1s 41us/step - loss: 0.4452 - acc: 0.8311\n",
      "Epoch 12/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.4330 - acc: 0.8340\n",
      "Epoch 13/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.4213 - acc: 0.8400\n",
      "Epoch 14/100\n",
      "16386/16386 [==============================] - 1s 41us/step - loss: 0.4178 - acc: 0.8402\n",
      "Epoch 15/100\n",
      "16386/16386 [==============================] - 1s 41us/step - loss: 0.4081 - acc: 0.8446\n",
      "Epoch 16/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.3987 - acc: 0.8451\n",
      "Epoch 17/100\n",
      "16386/16386 [==============================] - 1s 41us/step - loss: 0.3921 - acc: 0.8498\n",
      "Epoch 18/100\n",
      "16386/16386 [==============================] - 1s 39us/step - loss: 0.3815 - acc: 0.8519\n",
      "Epoch 19/100\n",
      "16386/16386 [==============================] - 1s 39us/step - loss: 0.3759 - acc: 0.8568\n",
      "Epoch 20/100\n",
      "16386/16386 [==============================] - 1s 39us/step - loss: 0.3686 - acc: 0.8592\n",
      "Epoch 21/100\n",
      "16386/16386 [==============================] - 1s 39us/step - loss: 0.3596 - acc: 0.8619\n",
      "Epoch 22/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.3524 - acc: 0.8647\n",
      "Epoch 23/100\n",
      "16386/16386 [==============================] - 1s 46us/step - loss: 0.3556 - acc: 0.8640\n",
      "Epoch 24/100\n",
      "16386/16386 [==============================] - 1s 43us/step - loss: 0.3352 - acc: 0.8724\n",
      "Epoch 25/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.3251 - acc: 0.8751\n",
      "Epoch 26/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.3225 - acc: 0.8734\n",
      "Epoch 27/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.3097 - acc: 0.8808\n",
      "Epoch 28/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.3099 - acc: 0.8809\n",
      "Epoch 29/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.2927 - acc: 0.8880\n",
      "Epoch 30/100\n",
      "16386/16386 [==============================] - 1s 39us/step - loss: 0.2915 - acc: 0.8889\n",
      "Epoch 31/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.2764 - acc: 0.8932\n",
      "Epoch 32/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.2694 - acc: 0.8966\n",
      "Epoch 33/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.2597 - acc: 0.8985\n",
      "Epoch 34/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.2535 - acc: 0.9018\n",
      "Epoch 35/100\n",
      "16386/16386 [==============================] - 1s 39us/step - loss: 0.2479 - acc: 0.9022\n",
      "Epoch 36/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.2381 - acc: 0.9103\n",
      "Epoch 37/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.2267 - acc: 0.9150\n",
      "Epoch 38/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.2206 - acc: 0.9161\n",
      "Epoch 39/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.2092 - acc: 0.9212\n",
      "Epoch 40/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.2107 - acc: 0.9217\n",
      "Epoch 41/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1960 - acc: 0.9256\n",
      "Epoch 42/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1962 - acc: 0.9251\n",
      "Epoch 43/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.1796 - acc: 0.9329\n",
      "Epoch 44/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1820 - acc: 0.9313\n",
      "Epoch 45/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.1714 - acc: 0.9373\n",
      "Epoch 46/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.1654 - acc: 0.9365\n",
      "Epoch 47/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1638 - acc: 0.9378\n",
      "Epoch 48/100\n",
      "16386/16386 [==============================] - 1s 39us/step - loss: 0.1462 - acc: 0.9476\n",
      "Epoch 49/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.1545 - acc: 0.9424\n",
      "Epoch 50/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1274 - acc: 0.9564\n",
      "Epoch 51/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1443 - acc: 0.9462\n",
      "Epoch 52/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.1341 - acc: 0.9498\n",
      "Epoch 53/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.1141 - acc: 0.9607\n",
      "Epoch 54/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1246 - acc: 0.9536\n",
      "Epoch 55/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.1135 - acc: 0.9610\n",
      "Epoch 56/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.0992 - acc: 0.9658\n",
      "Epoch 57/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.1071 - acc: 0.9608\n",
      "Epoch 58/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.1148 - acc: 0.9583\n",
      "Epoch 59/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0971 - acc: 0.9663\n",
      "Epoch 60/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.0836 - acc: 0.9717\n",
      "Epoch 61/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.0931 - acc: 0.9666\n",
      "Epoch 62/100\n",
      "16386/16386 [==============================] - 1s 42us/step - loss: 0.0901 - acc: 0.9681\n",
      "Epoch 63/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.0903 - acc: 0.9691\n",
      "Epoch 64/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0776 - acc: 0.9743\n",
      "Epoch 65/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.0807 - acc: 0.9718\n",
      "Epoch 66/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0939 - acc: 0.9674\n",
      "Epoch 67/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0601 - acc: 0.9812\n",
      "Epoch 68/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0703 - acc: 0.9755\n",
      "Epoch 69/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0796 - acc: 0.9727\n",
      "Epoch 70/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0580 - acc: 0.9821\n",
      "Epoch 71/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0525 - acc: 0.9835\n",
      "Epoch 72/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0724 - acc: 0.9760\n",
      "Epoch 73/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0598 - acc: 0.9802\n",
      "Epoch 74/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0677 - acc: 0.9766\n",
      "Epoch 75/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0574 - acc: 0.9819\n",
      "Epoch 76/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0769 - acc: 0.9755\n",
      "Epoch 77/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0702 - acc: 0.9757\n",
      "Epoch 78/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.0369 - acc: 0.9910\n",
      "Epoch 79/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0531 - acc: 0.9826\n",
      "Epoch 80/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.0711 - acc: 0.9740\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0484 - acc: 0.9842\n",
      "Epoch 82/100\n",
      "16386/16386 [==============================] - 1s 41us/step - loss: 0.0394 - acc: 0.9884\n",
      "Epoch 83/100\n",
      "16386/16386 [==============================] - 1s 43us/step - loss: 0.0341 - acc: 0.9903\n",
      "Epoch 84/100\n",
      "16386/16386 [==============================] - 1s 42us/step - loss: 0.0862 - acc: 0.9694\n",
      "Epoch 85/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.0533 - acc: 0.9820\n",
      "Epoch 86/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 87/100\n",
      "16386/16386 [==============================] - 1s 39us/step - loss: 0.0235 - acc: 0.9940\n",
      "Epoch 88/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.0586 - acc: 0.9811\n",
      "Epoch 89/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.0777 - acc: 0.9746\n",
      "Epoch 90/100\n",
      "16386/16386 [==============================] - 1s 44us/step - loss: 0.0414 - acc: 0.9882\n",
      "Epoch 91/100\n",
      "16386/16386 [==============================] - 1s 39us/step - loss: 0.0317 - acc: 0.9907\n",
      "Epoch 92/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0369 - acc: 0.9899\n",
      "Epoch 93/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0270 - acc: 0.9929\n",
      "Epoch 94/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.0298 - acc: 0.9903\n",
      "Epoch 95/100\n",
      "16386/16386 [==============================] - 1s 48us/step - loss: 0.1192 - acc: 0.9591\n",
      "Epoch 96/100\n",
      "16386/16386 [==============================] - 1s 45us/step - loss: 0.0394 - acc: 0.9881\n",
      "Epoch 97/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.0145 - acc: 0.9977\n",
      "Epoch 98/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0612 - acc: 0.9798\n",
      "Epoch 99/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0411 - acc: 0.9855\n",
      "Epoch 100/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0310 - acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3c80e48d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(X, dummy_y, epochs=100, batch_size=32) #Attention aux paramètres, certains changement provoquent l'overfitting !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16386/16386 [==============================] - 0s 16us/step\n",
      "\n",
      "loss: 2.39%\n",
      "\n",
      "acc: 99.27%\n"
     ]
    }
   ],
   "source": [
    "# evaluation du modèle\n",
    "scores = model.evaluate(X, dummy_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilisée pour calculer les effectifs par classe\n",
    "def counter(attr) :\n",
    "    unique, counts = numpy.unique(attr, return_counts=True)\n",
    "    return dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A2' 'B1' 'A1' ... 'A1' 'B1' 'A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noctis\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#predictions = model.predict(X)\n",
    "predictions = model.predict_classes(X_test)\n",
    "classes = encoder.inverse_transform(predictions)\n",
    "\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': 4662, 'A2': 2844, 'B1': 2276, 'B2': 913, 'C1': 214, 'C2': 15}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(classes,label=\"Count\")\n",
    "#plt.show()\n",
    "\n",
    "counter(classes)\n",
    "\n",
    "#Bizarrement, il peut etre nécéssaire de lancer 2 fois pour obtenir l'affichage\n",
    "#Bizarrement2 : l'ordre de l'affihage des classes n'est pas le meme sur les courbes, on a pas su trouver pourquoi :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': 4543, 'A2': 3072, 'B1': 2137, 'B2': 955, 'C1': 195, 'C2': 22}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.countplot(y_test,label=\"Count\")\n",
    "#plt.show()\n",
    "\n",
    "  \n",
    "counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"DONNES/train_cap2018.csv\")\n",
    "dataset = dataframe.values\n",
    "\n",
    "X = dataframe.iloc[:,1:59]\n",
    "Y = dataframe.iloc[:,59]\n",
    "\n",
    "X, X_test, Y, y_test = train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "where_are_NaNs = numpy.isnan(X) #Remplace les valeurs NaN par des 0\n",
    "X[where_are_NaNs] = 0\n",
    "\n",
    "where_are_NaNs = numpy.isnan(X_test) #Remplace les valeurs NaN par des 0\n",
    "X_test[where_are_NaNs] = 0\n",
    "\n",
    "#print(X)\n",
    "\n",
    "#Normalisation \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#print(X)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "#print(encoded_Y)\n",
    "#list(encoder.inverse_transform(encoded_Y)) la démarche inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(100, input_dim=58, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(500, activation='relu'))\n",
    "\tmodel.add(Dense(6, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20482/20482 [==============================] - 1s 44us/step - loss: 0.7027 - acc: 0.7288\n",
      "Epoch 2/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.5860 - acc: 0.7744\n",
      "Epoch 3/100\n",
      "20482/20482 [==============================] - 1s 35us/step - loss: 0.5449 - acc: 0.7923\n",
      "Epoch 4/100\n",
      "20482/20482 [==============================] - 1s 36us/step - loss: 0.5202 - acc: 0.8028\n",
      "Epoch 5/100\n",
      "20482/20482 [==============================] - 1s 36us/step - loss: 0.5000 - acc: 0.8103\n",
      "Epoch 6/100\n",
      "20482/20482 [==============================] - 1s 35us/step - loss: 0.4915 - acc: 0.8119\n",
      "Epoch 7/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.4753 - acc: 0.8194\n",
      "Epoch 8/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.4664 - acc: 0.8193\n",
      "Epoch 9/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.4549 - acc: 0.8267\n",
      "Epoch 10/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.4445 - acc: 0.8284\n",
      "Epoch 11/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.4356 - acc: 0.8320\n",
      "Epoch 12/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.4289 - acc: 0.8367\n",
      "Epoch 13/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.4178 - acc: 0.8390\n",
      "Epoch 14/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.4113 - acc: 0.8426\n",
      "Epoch 15/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.4037 - acc: 0.8438\n",
      "Epoch 16/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.3989 - acc: 0.8449\n",
      "Epoch 17/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.3889 - acc: 0.8500\n",
      "Epoch 18/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.3841 - acc: 0.8510\n",
      "Epoch 19/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.3752 - acc: 0.8573\n",
      "Epoch 20/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.3643 - acc: 0.8601\n",
      "Epoch 21/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.3593 - acc: 0.8616\n",
      "Epoch 22/100\n",
      "20482/20482 [==============================] - 1s 37us/step - loss: 0.3493 - acc: 0.8628\n",
      "Epoch 23/100\n",
      "20482/20482 [==============================] - 1s 38us/step - loss: 0.3433 - acc: 0.8675\n",
      "Epoch 24/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.3355 - acc: 0.8686\n",
      "Epoch 25/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.3264 - acc: 0.8736\n",
      "Epoch 26/100\n",
      "20482/20482 [==============================] - 1s 31us/step - loss: 0.3246 - acc: 0.8749\n",
      "Epoch 27/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.3113 - acc: 0.8803\n",
      "Epoch 28/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.3037 - acc: 0.8829\n",
      "Epoch 29/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.2982 - acc: 0.8857\n",
      "Epoch 30/100\n",
      "20482/20482 [==============================] - 1s 31us/step - loss: 0.2904 - acc: 0.8888\n",
      "Epoch 31/100\n",
      "20482/20482 [==============================] - 1s 31us/step - loss: 0.2794 - acc: 0.8924\n",
      "Epoch 32/100\n",
      "20482/20482 [==============================] - 1s 31us/step - loss: 0.2722 - acc: 0.8960\n",
      "Epoch 33/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.2671 - acc: 0.8979\n",
      "Epoch 34/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.2566 - acc: 0.9024\n",
      "Epoch 35/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.2531 - acc: 0.9009\n",
      "Epoch 36/100\n",
      "20482/20482 [==============================] - 1s 31us/step - loss: 0.2412 - acc: 0.9073\n",
      "Epoch 37/100\n",
      "20482/20482 [==============================] - 1s 45us/step - loss: 0.2382 - acc: 0.9084\n",
      "Epoch 38/100\n",
      "20482/20482 [==============================] - 1s 44us/step - loss: 0.2273 - acc: 0.9129\n",
      "Epoch 39/100\n",
      "20482/20482 [==============================] - 1s 43us/step - loss: 0.2222 - acc: 0.9167\n",
      "Epoch 40/100\n",
      "20482/20482 [==============================] - 1s 54us/step - loss: 0.2146 - acc: 0.9171\n",
      "Epoch 41/100\n",
      "20482/20482 [==============================] - 1s 50us/step - loss: 0.2031 - acc: 0.9213\n",
      "Epoch 42/100\n",
      "20482/20482 [==============================] - 1s 37us/step - loss: 0.2040 - acc: 0.9217\n",
      "Epoch 43/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.1913 - acc: 0.9272\n",
      "Epoch 44/100\n",
      "20482/20482 [==============================] - 1s 31us/step - loss: 0.1855 - acc: 0.9294\n",
      "Epoch 45/100\n",
      "20482/20482 [==============================] - 1s 38us/step - loss: 0.1785 - acc: 0.9320\n",
      "Epoch 46/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.1734 - acc: 0.9342\n",
      "Epoch 47/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.1753 - acc: 0.9326\n",
      "Epoch 48/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.1609 - acc: 0.9378\n",
      "Epoch 49/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.1550 - acc: 0.9412\n",
      "Epoch 50/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.1496 - acc: 0.9435\n",
      "Epoch 51/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.1390 - acc: 0.9482\n",
      "Epoch 52/100\n",
      "20482/20482 [==============================] - 1s 36us/step - loss: 0.1356 - acc: 0.9489\n",
      "Epoch 53/100\n",
      "20482/20482 [==============================] - 1s 35us/step - loss: 0.1397 - acc: 0.9476\n",
      "Epoch 54/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.1307 - acc: 0.9517\n",
      "Epoch 55/100\n",
      "20482/20482 [==============================] - 1s 35us/step - loss: 0.1247 - acc: 0.9533\n",
      "Epoch 56/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.1216 - acc: 0.9556\n",
      "Epoch 57/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.1070 - acc: 0.9601\n",
      "Epoch 58/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.1123 - acc: 0.9589\n",
      "Epoch 59/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.1042 - acc: 0.9636\n",
      "Epoch 60/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.1111 - acc: 0.9593\n",
      "Epoch 61/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.1064 - acc: 0.9628\n",
      "Epoch 62/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.0918 - acc: 0.9664\n",
      "Epoch 63/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.1008 - acc: 0.9632\n",
      "Epoch 64/100\n",
      "20482/20482 [==============================] - 1s 31us/step - loss: 0.0939 - acc: 0.9672\n",
      "Epoch 65/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0783 - acc: 0.9722\n",
      "Epoch 66/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0875 - acc: 0.9683\n",
      "Epoch 67/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.0955 - acc: 0.9674\n",
      "Epoch 68/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0715 - acc: 0.9753\n",
      "Epoch 69/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0672 - acc: 0.9772\n",
      "Epoch 70/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0789 - acc: 0.9736\n",
      "Epoch 71/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0761 - acc: 0.9725\n",
      "Epoch 72/100\n",
      "20482/20482 [==============================] - 1s 31us/step - loss: 0.0672 - acc: 0.9781\n",
      "Epoch 73/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0953 - acc: 0.9661\n",
      "Epoch 74/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0630 - acc: 0.9778\n",
      "Epoch 75/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0639 - acc: 0.9786\n",
      "Epoch 76/100\n",
      "20482/20482 [==============================] - 1s 31us/step - loss: 0.0588 - acc: 0.9804\n",
      "Epoch 77/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.0558 - acc: 0.9817\n",
      "Epoch 78/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.0666 - acc: 0.9769\n",
      "Epoch 79/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.0636 - acc: 0.9776\n",
      "Epoch 80/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0587 - acc: 0.9793\n",
      "Epoch 81/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.0634 - acc: 0.9779\n",
      "Epoch 82/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.0598 - acc: 0.9796\n",
      "Epoch 83/100\n",
      "20482/20482 [==============================] - 1s 35us/step - loss: 0.0662 - acc: 0.9788\n",
      "Epoch 84/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0355 - acc: 0.9900\n",
      "Epoch 85/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0396 - acc: 0.9880\n",
      "Epoch 86/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0802 - acc: 0.9725\n",
      "Epoch 87/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.0522 - acc: 0.9828\n",
      "Epoch 88/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0697 - acc: 0.9772\n",
      "Epoch 89/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0378 - acc: 0.9883\n",
      "Epoch 90/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0459 - acc: 0.9861\n",
      "Epoch 91/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.0683 - acc: 0.9762\n",
      "Epoch 92/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0547 - acc: 0.9814\n",
      "Epoch 93/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0604 - acc: 0.9813\n",
      "Epoch 94/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.0345 - acc: 0.9895\n",
      "Epoch 95/100\n",
      "20482/20482 [==============================] - 1s 36us/step - loss: 0.0540 - acc: 0.9831\n",
      "Epoch 96/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.0543 - acc: 0.9809\n",
      "Epoch 97/100\n",
      "20482/20482 [==============================] - 1s 33us/step - loss: 0.0496 - acc: 0.9831\n",
      "Epoch 98/100\n",
      "20482/20482 [==============================] - 1s 34us/step - loss: 0.0434 - acc: 0.9858\n",
      "Epoch 99/100\n",
      "20482/20482 [==============================] - 1s 31us/step - loss: 0.0396 - acc: 0.9870\n",
      "Epoch 100/100\n",
      "20482/20482 [==============================] - 1s 32us/step - loss: 0.0603 - acc: 0.9794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1875882b048>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(X, dummy_y, epochs=100, batch_size=32) #Attention aux paramètres, certains changement provoquent l'overfitting !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20482/20482 [==============================] - 0s 16us/step\n",
      "\n",
      "loss: 5.00%\n",
      "\n",
      "acc: 98.34%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, dummy_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(attr) :\n",
    "    unique, counts = numpy.unique(attr, return_counts=True)\n",
    "    return dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A2' 'B1' 'A1' ... 'A1' 'A2' 'B2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noctis\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#predictions = model.predict(X)\n",
    "predictions = model.predict_classes(X_test)\n",
    "classes = encoder.inverse_transform(predictions)\n",
    "\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'A1': 2859, 'A2': 1907, 'B1': 1360, 'B2': 562, 'C1': 131, 'C2': 9}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(type(classes))\n",
    "#rclasses = classes[::-1]\n",
    "\n",
    "sns.countplot(classes,label=\"Count\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "counter(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'A1': 2865, 'A2': 1906, 'B1': 1336, 'B2': 587, 'C1': 120, 'C2': 14}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.countplot(y_test,label=\"Count\")\n",
    "plt.show()\n",
    "\n",
    "  \n",
    "counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maintenant qu'on a construit, entrainé et testé sur les données \"train\" notre réseau\n",
    "#Il nous faut l'utiliser sur des données non étiquettées\n",
    "#Ce sont les données dans le fichier test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.    39.   142.   ...   0.82  29.47 105.19]\n",
      " [  7.    42.   182.   ...   0.74  19.98 260.77]\n",
      " [  9.    86.   299.   ...   0.62  17.8  164.95]\n",
      " ...\n",
      " [  1.   110.   425.   ...   0.66  23.4  109.09]\n",
      " [  2.    26.   118.   ...   0.88  37.6   88.76]\n",
      " [ 10.    68.   288.   ...   0.66  18.73 259.52]]\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv(\"DONNES/test_cap2018.csv\")\n",
    "don =  df.iloc[:,1:59]\n",
    "\n",
    "\n",
    "\n",
    "#Normalisation des données : \n",
    "\n",
    "\n",
    "\n",
    "where_are_NaNs = numpy.isnan(don) #Remplace les valeurs NaN par des 0\n",
    "don[where_are_NaNs] = 0\n",
    "\n",
    "#Normalisation \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "don = scaler.transform(don)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

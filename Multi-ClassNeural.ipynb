{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noctis\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"DONNES/train_cap2018.csv\")\n",
    "dataset = dataframe.values\n",
    "\n",
    "X = dataframe.iloc[:,1:59]\n",
    "Y = dataframe.iloc[:,59]\n",
    "\n",
    "X, X_test, Y, y_test = train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "where_are_NaNs = numpy.isnan(X) #Remplace les valeurs NaN par des 0\n",
    "X[where_are_NaNs] = 0\n",
    "\n",
    "where_are_NaNs = numpy.isnan(X_test) #Remplace les valeurs NaN par des 0\n",
    "X_test[where_are_NaNs] = 0\n",
    "\n",
    "#print(X)\n",
    "\n",
    "#Normalisation \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X = scaler.transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#print(X)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "#print(encoded_Y)\n",
    "#list(encoder.inverse_transform(encoded_Y)) la d√©marche inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(100, input_dim=58, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(500, activation='relu'))\n",
    "\tmodel.add(Dense(6, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16386/16386 [==============================] - 1s 48us/step - loss: 0.7315 - acc: 0.7145\n",
      "Epoch 2/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.5985 - acc: 0.7716\n",
      "Epoch 3/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.5660 - acc: 0.7841\n",
      "Epoch 4/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.5348 - acc: 0.7946\n",
      "Epoch 5/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.5135 - acc: 0.8017\n",
      "Epoch 6/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.4993 - acc: 0.8083\n",
      "Epoch 7/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.4840 - acc: 0.8150\n",
      "Epoch 8/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.4731 - acc: 0.8203\n",
      "Epoch 9/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.4609 - acc: 0.8217\n",
      "Epoch 10/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.4546 - acc: 0.8258\n",
      "Epoch 11/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.4487 - acc: 0.8286\n",
      "Epoch 12/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.4390 - acc: 0.8324\n",
      "Epoch 13/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.4242 - acc: 0.8383\n",
      "Epoch 14/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.4205 - acc: 0.8393\n",
      "Epoch 15/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.4110 - acc: 0.8404\n",
      "Epoch 16/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.4008 - acc: 0.8451\n",
      "Epoch 17/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.3956 - acc: 0.8461\n",
      "Epoch 18/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.3863 - acc: 0.8518\n",
      "Epoch 19/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.3789 - acc: 0.8530\n",
      "Epoch 20/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.3717 - acc: 0.8560\n",
      "Epoch 21/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.3615 - acc: 0.8585\n",
      "Epoch 22/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.3581 - acc: 0.8615\n",
      "Epoch 23/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.3535 - acc: 0.8645\n",
      "Epoch 24/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.3409 - acc: 0.8679\n",
      "Epoch 25/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.3291 - acc: 0.8713\n",
      "Epoch 26/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.3224 - acc: 0.8718\n",
      "Epoch 27/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.3153 - acc: 0.8772\n",
      "Epoch 28/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.3180 - acc: 0.8776\n",
      "Epoch 29/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.2986 - acc: 0.8828\n",
      "Epoch 30/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.2920 - acc: 0.8891\n",
      "Epoch 31/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.2846 - acc: 0.8907\n",
      "Epoch 32/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.2777 - acc: 0.8933\n",
      "Epoch 33/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.2651 - acc: 0.8969\n",
      "Epoch 34/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.2587 - acc: 0.8981\n",
      "Epoch 35/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.2535 - acc: 0.9013\n",
      "Epoch 36/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.2444 - acc: 0.9072\n",
      "Epoch 37/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.2353 - acc: 0.9114\n",
      "Epoch 38/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.2272 - acc: 0.9117\n",
      "Epoch 39/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.2215 - acc: 0.9144\n",
      "Epoch 40/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.2131 - acc: 0.9199\n",
      "Epoch 41/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.2043 - acc: 0.9207\n",
      "Epoch 42/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.2010 - acc: 0.9230\n",
      "Epoch 43/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.1873 - acc: 0.9294\n",
      "Epoch 44/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.1838 - acc: 0.9301\n",
      "Epoch 45/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.1797 - acc: 0.9313\n",
      "Epoch 46/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1725 - acc: 0.9330\n",
      "Epoch 47/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.1690 - acc: 0.9346\n",
      "Epoch 48/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1521 - acc: 0.9439\n",
      "Epoch 49/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.1584 - acc: 0.9411\n",
      "Epoch 50/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1402 - acc: 0.9516\n",
      "Epoch 51/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.1455 - acc: 0.9468\n",
      "Epoch 52/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.1377 - acc: 0.9500\n",
      "Epoch 53/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.1174 - acc: 0.9589\n",
      "Epoch 54/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.1271 - acc: 0.9531\n",
      "Epoch 55/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.1160 - acc: 0.9584\n",
      "Epoch 56/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.1149 - acc: 0.9579\n",
      "Epoch 57/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.1102 - acc: 0.9595\n",
      "Epoch 58/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.1034 - acc: 0.9643\n",
      "Epoch 59/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.1018 - acc: 0.9640\n",
      "Epoch 60/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0966 - acc: 0.9667\n",
      "Epoch 61/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0985 - acc: 0.9647\n",
      "Epoch 62/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.1108 - acc: 0.9606\n",
      "Epoch 63/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0893 - acc: 0.9702\n",
      "Epoch 64/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.0739 - acc: 0.9747\n",
      "Epoch 65/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.0786 - acc: 0.9735\n",
      "Epoch 66/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0840 - acc: 0.9720\n",
      "Epoch 67/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0757 - acc: 0.9762\n",
      "Epoch 68/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0974 - acc: 0.9656\n",
      "Epoch 69/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0693 - acc: 0.9767\n",
      "Epoch 70/100\n",
      "16386/16386 [==============================] - 1s 38us/step - loss: 0.0547 - acc: 0.9832\n",
      "Epoch 71/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.0702 - acc: 0.9768\n",
      "Epoch 72/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0772 - acc: 0.9729\n",
      "Epoch 73/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0683 - acc: 0.9766\n",
      "Epoch 74/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.0622 - acc: 0.9797\n",
      "Epoch 75/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.0590 - acc: 0.9821\n",
      "Epoch 76/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0488 - acc: 0.9848\n",
      "Epoch 77/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.0654 - acc: 0.9772\n",
      "Epoch 78/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.0590 - acc: 0.9802\n",
      "Epoch 79/100\n",
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0521 - acc: 0.9830\n",
      "Epoch 80/100\n",
      "16386/16386 [==============================] - 1s 40us/step - loss: 0.0597 - acc: 0.9803\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16386/16386 [==============================] - 1s 36us/step - loss: 0.0376 - acc: 0.9893\n",
      "Epoch 82/100\n",
      "16386/16386 [==============================] - 1s 37us/step - loss: 0.0758 - acc: 0.9743\n",
      "Epoch 83/100\n",
      "16386/16386 [==============================] - 1s 35us/step - loss: 0.0652 - acc: 0.9789\n",
      "Epoch 84/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0453 - acc: 0.9857\n",
      "Epoch 85/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0217 - acc: 0.9946\n",
      "Epoch 86/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.0694 - acc: 0.9755\n",
      "Epoch 87/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0669 - acc: 0.9767\n",
      "Epoch 88/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0458 - acc: 0.9852\n",
      "Epoch 89/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0237 - acc: 0.9946\n",
      "Epoch 90/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0220 - acc: 0.9942\n",
      "Epoch 91/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.0928 - acc: 0.9694\n",
      "Epoch 92/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.0492 - acc: 0.9844\n",
      "Epoch 93/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0292 - acc: 0.9916\n",
      "Epoch 94/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0385 - acc: 0.9885\n",
      "Epoch 95/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0559 - acc: 0.9798\n",
      "Epoch 96/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0332 - acc: 0.9897\n",
      "Epoch 97/100\n",
      "16386/16386 [==============================] - 1s 34us/step - loss: 0.0414 - acc: 0.9867\n",
      "Epoch 98/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0697 - acc: 0.9767\n",
      "Epoch 99/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0260 - acc: 0.9932\n",
      "Epoch 100/100\n",
      "16386/16386 [==============================] - 1s 33us/step - loss: 0.0557 - acc: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b816f82f98>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(X, dummy_y, epochs=100, batch_size=32) #Attention aux param√®tres, certains changement provoquent l'overfitting !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16386/16386 [==============================] - 0s 16us/step\n",
      "\n",
      "loss: 5.04%\n",
      "\n",
      "acc: 98.29%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, dummy_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(attr) :\n",
    "    unique, counts = numpy.unique(attr, return_counts=True)\n",
    "    return dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A2' 'B1' 'A1' ... 'A1' 'B1' 'A2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noctis\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#predictions = model.predict(X)\n",
    "predictions = model.predict_classes(X_test)\n",
    "classes = encoder.inverse_transform(predictions)\n",
    "\n",
    "print(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'A1': 4375, 'A2': 3268, 'B1': 2222, 'B2': 755, 'C1': 287, 'C2': 17}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(type(classes))\n",
    "#rclasses = classes[::-1]\n",
    "\n",
    "sns.countplot(classes,label=\"Count\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "counter(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'A1': 4543, 'A2': 3072, 'B1': 2137, 'B2': 955, 'C1': 195, 'C2': 22}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.countplot(y_test,label=\"Count\")\n",
    "plt.show()\n",
    "\n",
    "  \n",
    "counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maintenant qu'on a construit, entrain√© et test√© sur les donn√©es \"train\" notre r√©seau\n",
    "#Il nous faut l'utiliser sur des donn√©es non √©tiquett√©es\n",
    "#Ce sont les donn√©es dans le fichier test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.    39.   142.   ...   0.82  29.47 105.19]\n",
      " [  7.    42.   182.   ...   0.74  19.98 260.77]\n",
      " [  9.    86.   299.   ...   0.62  17.8  164.95]\n",
      " ...\n",
      " [  1.   110.   425.   ...   0.66  23.4  109.09]\n",
      " [  2.    26.   118.   ...   0.88  37.6   88.76]\n",
      " [ 10.    68.   288.   ...   0.66  18.73 259.52]]\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv(\"DONNES/test_cap2018.csv\")\n",
    "don =  df.iloc[:,1:59]\n",
    "\n",
    "\n",
    "\n",
    "#Normalisation des donn√©es : \n",
    "\n",
    "\n",
    "\n",
    "where_are_NaNs = numpy.isnan(don) #Remplace les valeurs NaN par des 0\n",
    "don[where_are_NaNs] = 0\n",
    "\n",
    "#Normalisation \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "don = scaler.transform(don)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

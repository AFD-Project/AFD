{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.600e+01 2.330e+02 1.116e+03 ... 8.800e-01 5.900e-01 2.430e+01]\n",
      " [7.000e+00 1.800e+02 8.660e+02 ... 8.900e-01 6.400e-01 2.614e+01]\n",
      " [1.000e+01 1.800e+02 8.610e+02 ... 9.200e-01 7.200e-01 3.515e+01]\n",
      " ...\n",
      " [2.000e+00 2.000e+01 6.300e+01 ... 8.600e-01 9.000e-01 3.699e+01]\n",
      " [5.000e+00 2.700e+01 1.070e+02 ... 8.600e-01 8.500e-01 2.942e+01]\n",
      " [1.000e+00 3.800e+01 1.740e+02 ... 7.800e-01 7.100e-01 1.682e+01]]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"DONNES/train_cap2018.csv\")\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,1:58].astype(float)\n",
    "Y = dataset[:,59]\n",
    "\n",
    "where_are_NaNs = numpy.isnan(X) #Remplace les valeurs NaN par des 0\n",
    "X[where_are_NaNs] = 0\n",
    "\n",
    "print(X)\n",
    "#Normalisation \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X = scaler.transform(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "#print(X)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "#print(encoded_Y)\n",
    "#list(encoder.inverse_transform(encoded_Y)) la démarche inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(10, input_dim=57,kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(10, activation='relu'))\n",
    "\tmodel.add(Dense(6, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "27310/27310 [==============================] - 4s 138us/step - loss: 0.9105 - acc: 0.6391\n",
      "Epoch 2/150\n",
      "27310/27310 [==============================] - 3s 109us/step - loss: 0.7830 - acc: 0.6908\n",
      "Epoch 3/150\n",
      "27310/27310 [==============================] - 3s 120us/step - loss: 0.7736 - acc: 0.6956\n",
      "Epoch 4/150\n",
      "27310/27310 [==============================] - 3s 109us/step - loss: 0.7693 - acc: 0.6956\n",
      "Epoch 5/150\n",
      "27310/27310 [==============================] - 4s 137us/step - loss: 0.7666 - acc: 0.6992\n",
      "Epoch 6/150\n",
      "27310/27310 [==============================] - 3s 122us/step - loss: 0.7615 - acc: 0.7014\n",
      "Epoch 7/150\n",
      "27310/27310 [==============================] - 4s 137us/step - loss: 0.7612 - acc: 0.6986\n",
      "Epoch 8/150\n",
      "27310/27310 [==============================] - 5s 168us/step - loss: 0.7589 - acc: 0.7003\n",
      "Epoch 9/150\n",
      "27310/27310 [==============================] - 5s 168us/step - loss: 0.7552 - acc: 0.7016\n",
      "Epoch 10/150\n",
      "27310/27310 [==============================] - 4s 145us/step - loss: 0.7543 - acc: 0.7034\n",
      "Epoch 11/150\n",
      "27310/27310 [==============================] - 4s 143us/step - loss: 0.7550 - acc: 0.7025\n",
      "Epoch 12/150\n",
      "27310/27310 [==============================] - 4s 149us/step - loss: 0.7528 - acc: 0.7037\n",
      "Epoch 13/150\n",
      "27310/27310 [==============================] - 4s 162us/step - loss: 0.7518 - acc: 0.7037\n",
      "Epoch 14/150\n",
      "27310/27310 [==============================] - 5s 175us/step - loss: 0.7514 - acc: 0.7034\n",
      "Epoch 15/150\n",
      "27310/27310 [==============================] - 5s 187us/step - loss: 0.7502 - acc: 0.7023\n",
      "Epoch 16/150\n",
      "27310/27310 [==============================] - 5s 185us/step - loss: 0.7498 - acc: 0.7028\n",
      "Epoch 17/150\n",
      "27310/27310 [==============================] - 5s 182us/step - loss: 0.7486 - acc: 0.7037\n",
      "Epoch 18/150\n",
      "27310/27310 [==============================] - 4s 152us/step - loss: 0.7459 - acc: 0.7064\n",
      "Epoch 19/150\n",
      "27310/27310 [==============================] - 3s 109us/step - loss: 0.7469 - acc: 0.7056\n",
      "Epoch 20/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7472 - acc: 0.7056\n",
      "Epoch 21/150\n",
      "27310/27310 [==============================] - 3s 125us/step - loss: 0.7466 - acc: 0.7042\n",
      "Epoch 22/150\n",
      "27310/27310 [==============================] - 4s 130us/step - loss: 0.7441 - acc: 0.7095\n",
      "Epoch 23/150\n",
      "27310/27310 [==============================] - 3s 124us/step - loss: 0.7446 - acc: 0.7078 \n",
      "Epoch 24/150\n",
      "27310/27310 [==============================] - 4s 133us/step - loss: 0.7429 - acc: 0.7050\n",
      "Epoch 25/150\n",
      "27310/27310 [==============================] - 3s 121us/step - loss: 0.7439 - acc: 0.7052\n",
      "Epoch 26/150\n",
      "27310/27310 [==============================] - 3s 100us/step - loss: 0.7434 - acc: 0.7070\n",
      "Epoch 27/150\n",
      "27310/27310 [==============================] - 3s 100us/step - loss: 0.7420 - acc: 0.7062 1s - loss: \n",
      "Epoch 28/150\n",
      "27310/27310 [==============================] - 4s 131us/step - loss: 0.7417 - acc: 0.7054\n",
      "Epoch 29/150\n",
      "27310/27310 [==============================] - 3s 123us/step - loss: 0.7414 - acc: 0.7070\n",
      "Epoch 30/150\n",
      "27310/27310 [==============================] - 4s 162us/step - loss: 0.7398 - acc: 0.7088\n",
      "Epoch 31/150\n",
      "27310/27310 [==============================] - 4s 150us/step - loss: 0.7398 - acc: 0.7079\n",
      "Epoch 32/150\n",
      "27310/27310 [==============================] - 4s 134us/step - loss: 0.7379 - acc: 0.7080\n",
      "Epoch 33/150\n",
      "27310/27310 [==============================] - ETA: 0s - loss: 0.7379 - acc: 0.707 - 3s 122us/step - loss: 0.7384 - acc: 0.7071\n",
      "Epoch 34/150\n",
      "27310/27310 [==============================] - 3s 122us/step - loss: 0.7396 - acc: 0.7074\n",
      "Epoch 35/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7382 - acc: 0.7082\n",
      "Epoch 36/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7373 - acc: 0.7107 0s - loss: 0.7336\n",
      "Epoch 37/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7365 - acc: 0.7099\n",
      "Epoch 38/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7368 - acc: 0.7086\n",
      "Epoch 39/150\n",
      "27310/27310 [==============================] - 4s 129us/step - loss: 0.7350 - acc: 0.7106\n",
      "Epoch 40/150\n",
      "27310/27310 [==============================] - 3s 121us/step - loss: 0.7363 - acc: 0.7096\n",
      "Epoch 41/150\n",
      "27310/27310 [==============================] - 3s 126us/step - loss: 0.7363 - acc: 0.7069\n",
      "Epoch 42/150\n",
      "27310/27310 [==============================] - 3s 120us/step - loss: 0.7362 - acc: 0.7078\n",
      "Epoch 43/150\n",
      "27310/27310 [==============================] - 3s 122us/step - loss: 0.7342 - acc: 0.7109\n",
      "Epoch 44/150\n",
      "27310/27310 [==============================] - 3s 120us/step - loss: 0.7347 - acc: 0.7085\n",
      "Epoch 45/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7338 - acc: 0.7115\n",
      "Epoch 46/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7335 - acc: 0.7092\n",
      "Epoch 47/150\n",
      "27310/27310 [==============================] - 3s 104us/step - loss: 0.7333 - acc: 0.7117\n",
      "Epoch 48/150\n",
      "27310/27310 [==============================] - 3s 104us/step - loss: 0.7335 - acc: 0.7107\n",
      "Epoch 49/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7313 - acc: 0.7101\n",
      "Epoch 50/150\n",
      "27310/27310 [==============================] - 3s 122us/step - loss: 0.7328 - acc: 0.7096\n",
      "Epoch 51/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7314 - acc: 0.7119\n",
      "Epoch 52/150\n",
      "27310/27310 [==============================] - 3s 121us/step - loss: 0.7310 - acc: 0.7131\n",
      "Epoch 53/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7300 - acc: 0.7115\n",
      "Epoch 54/150\n",
      "27310/27310 [==============================] - 3s 120us/step - loss: 0.7298 - acc: 0.7108\n",
      "Epoch 55/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7303 - acc: 0.7115\n",
      "Epoch 56/150\n",
      "27310/27310 [==============================] - 3s 113us/step - loss: 0.7294 - acc: 0.7114\n",
      "Epoch 57/150\n",
      "27310/27310 [==============================] - 3s 107us/step - loss: 0.7306 - acc: 0.7100\n",
      "Epoch 58/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7287 - acc: 0.7124\n",
      "Epoch 59/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7284 - acc: 0.7133\n",
      "Epoch 60/150\n",
      "27310/27310 [==============================] - 3s 120us/step - loss: 0.7295 - acc: 0.7115\n",
      "Epoch 61/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7280 - acc: 0.7124\n",
      "Epoch 62/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7269 - acc: 0.7128 0s - loss:\n",
      "Epoch 63/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7276 - acc: 0.7104\n",
      "Epoch 64/150\n",
      "27310/27310 [==============================] - 3s 114us/step - loss: 0.7276 - acc: 0.7121\n",
      "Epoch 65/150\n",
      "27310/27310 [==============================] - 3s 113us/step - loss: 0.7257 - acc: 0.7127\n",
      "Epoch 66/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7261 - acc: 0.7120\n",
      "Epoch 67/150\n",
      "27310/27310 [==============================] - 3s 109us/step - loss: 0.7267 - acc: 0.7122\n",
      "Epoch 68/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7259 - acc: 0.7115 1s - los\n",
      "Epoch 69/150\n",
      "27310/27310 [==============================] - 3s 114us/step - loss: 0.7254 - acc: 0.7127\n",
      "Epoch 70/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7262 - acc: 0.7116\n",
      "Epoch 71/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7248 - acc: 0.7118\n",
      "Epoch 72/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7245 - acc: 0.7150\n",
      "Epoch 73/150\n",
      "27310/27310 [==============================] - 3s 114us/step - loss: 0.7232 - acc: 0.7142\n",
      "Epoch 74/150\n",
      "27310/27310 [==============================] - 3s 112us/step - loss: 0.7239 - acc: 0.7133\n",
      "Epoch 75/150\n",
      "27310/27310 [==============================] - 3s 113us/step - loss: 0.7241 - acc: 0.7123\n",
      "Epoch 76/150\n",
      "27310/27310 [==============================] - 3s 107us/step - loss: 0.7234 - acc: 0.7124\n",
      "Epoch 77/150\n",
      "27310/27310 [==============================] - 3s 113us/step - loss: 0.7239 - acc: 0.7127\n",
      "Epoch 78/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7241 - acc: 0.7105\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27310/27310 [==============================] - 3s 100us/step - loss: 0.7229 - acc: 0.7122\n",
      "Epoch 80/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7230 - acc: 0.7147 0s - loss: 0.7219 - acc: \n",
      "Epoch 81/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7236 - acc: 0.7115\n",
      "Epoch 82/150\n",
      "27310/27310 [==============================] - 3s 101us/step - loss: 0.7228 - acc: 0.7128\n",
      "Epoch 83/150\n",
      "27310/27310 [==============================] - 3s 92us/step - loss: 0.7213 - acc: 0.7129\n",
      "Epoch 84/150\n",
      "27310/27310 [==============================] - 2s 90us/step - loss: 0.7220 - acc: 0.7152: 0s - loss: 0.7222 - acc:\n",
      "Epoch 85/150\n",
      "27310/27310 [==============================] - 3s 92us/step - loss: 0.7216 - acc: 0.7132\n",
      "Epoch 86/150\n",
      "27310/27310 [==============================] - 3s 107us/step - loss: 0.7211 - acc: 0.7151\n",
      "Epoch 87/150\n",
      "27310/27310 [==============================] - 3s 111us/step - loss: 0.7210 - acc: 0.7129\n",
      "Epoch 88/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7208 - acc: 0.7135\n",
      "Epoch 89/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7204 - acc: 0.7158\n",
      "Epoch 90/150\n",
      "27310/27310 [==============================] - 4s 147us/step - loss: 0.7215 - acc: 0.7144\n",
      "Epoch 91/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7223 - acc: 0.7140\n",
      "Epoch 92/150\n",
      "27310/27310 [==============================] - 3s 114us/step - loss: 0.7219 - acc: 0.7128\n",
      "Epoch 93/150\n",
      "27310/27310 [==============================] - 2s 88us/step - loss: 0.7212 - acc: 0.7156\n",
      "Epoch 94/150\n",
      "27310/27310 [==============================] - 3s 96us/step - loss: 0.7200 - acc: 0.7144\n",
      "Epoch 95/150\n",
      "27310/27310 [==============================] - 3s 95us/step - loss: 0.7215 - acc: 0.7140\n",
      "Epoch 96/150\n",
      "27310/27310 [==============================] - 3s 99us/step - loss: 0.7187 - acc: 0.7159\n",
      "Epoch 97/150\n",
      "27310/27310 [==============================] - 3s 108us/step - loss: 0.7213 - acc: 0.7153 1\n",
      "Epoch 98/150\n",
      "27310/27310 [==============================] - 3s 124us/step - loss: 0.7205 - acc: 0.7144\n",
      "Epoch 99/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7187 - acc: 0.7143\n",
      "Epoch 100/150\n",
      "27310/27310 [==============================] - 3s 117us/step - loss: 0.7192 - acc: 0.7159\n",
      "Epoch 101/150\n",
      "27310/27310 [==============================] - 4s 132us/step - loss: 0.7184 - acc: 0.7165\n",
      "Epoch 102/150\n",
      "27310/27310 [==============================] - 3s 123us/step - loss: 0.7187 - acc: 0.7140\n",
      "Epoch 103/150\n",
      "27310/27310 [==============================] - 3s 119us/step - loss: 0.7193 - acc: 0.7161\n",
      "Epoch 104/150\n",
      "27310/27310 [==============================] - 3s 98us/step - loss: 0.7185 - acc: 0.7149: 1s - loss: 0.7180 - acc - ETA: 0s - loss: 0.7196 -\n",
      "Epoch 105/150\n",
      "27310/27310 [==============================] - 3s 101us/step - loss: 0.7199 - acc: 0.7127\n",
      "Epoch 106/150\n",
      "27310/27310 [==============================] - 3s 126us/step - loss: 0.7174 - acc: 0.7167\n",
      "Epoch 107/150\n",
      "27310/27310 [==============================] - 3s 126us/step - loss: 0.7183 - acc: 0.7156\n",
      "Epoch 108/150\n",
      "27310/27310 [==============================] - 4s 130us/step - loss: 0.7202 - acc: 0.7156\n",
      "Epoch 109/150\n",
      "27310/27310 [==============================] - 3s 102us/step - loss: 0.7200 - acc: 0.7131 1s - loss:\n",
      "Epoch 110/150\n",
      "27310/27310 [==============================] - 3s 101us/step - loss: 0.7197 - acc: 0.7147\n",
      "Epoch 111/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7165 - acc: 0.7151\n",
      "Epoch 112/150\n",
      "27310/27310 [==============================] - 3s 109us/step - loss: 0.7177 - acc: 0.7162\n",
      "Epoch 113/150\n",
      "27310/27310 [==============================] - 3s 128us/step - loss: 0.7168 - acc: 0.7152\n",
      "Epoch 114/150\n",
      "27310/27310 [==============================] - 3s 126us/step - loss: 0.7166 - acc: 0.7139\n",
      "Epoch 115/150\n",
      "27310/27310 [==============================] - 3s 122us/step - loss: 0.7165 - acc: 0.7152\n",
      "Epoch 116/150\n",
      "27310/27310 [==============================] - 3s 125us/step - loss: 0.7155 - acc: 0.7163\n",
      "Epoch 117/150\n",
      "27310/27310 [==============================] - 3s 127us/step - loss: 0.7152 - acc: 0.7176\n",
      "Epoch 118/150\n",
      "27310/27310 [==============================] - 3s 124us/step - loss: 0.7146 - acc: 0.7187\n",
      "Epoch 119/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7153 - acc: 0.7162\n",
      "Epoch 120/150\n",
      "27310/27310 [==============================] - 3s 104us/step - loss: 0.7149 - acc: 0.7176\n",
      "Epoch 121/150\n",
      "27310/27310 [==============================] - 3s 103us/step - loss: 0.7141 - acc: 0.7170\n",
      "Epoch 122/150\n",
      "27310/27310 [==============================] - 3s 101us/step - loss: 0.7153 - acc: 0.7163\n",
      "Epoch 123/150\n",
      "27310/27310 [==============================] - 3s 123us/step - loss: 0.7135 - acc: 0.7168\n",
      "Epoch 124/150\n",
      "27310/27310 [==============================] - 3s 123us/step - loss: 0.7136 - acc: 0.7194\n",
      "Epoch 125/150\n",
      "27310/27310 [==============================] - 4s 148us/step - loss: 0.7145 - acc: 0.7167\n",
      "Epoch 126/150\n",
      "27310/27310 [==============================] - 3s 122us/step - loss: 0.7143 - acc: 0.7171\n",
      "Epoch 127/150\n",
      "27310/27310 [==============================] - 3s 121us/step - loss: 0.7129 - acc: 0.7171\n",
      "Epoch 128/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7120 - acc: 0.7179\n",
      "Epoch 129/150\n",
      "27310/27310 [==============================] - 3s 107us/step - loss: 0.7120 - acc: 0.7187\n",
      "Epoch 130/150\n",
      "27310/27310 [==============================] - 4s 132us/step - loss: 0.7123 - acc: 0.7199\n",
      "Epoch 131/150\n",
      "27310/27310 [==============================] - 3s 111us/step - loss: 0.7123 - acc: 0.7181\n",
      "Epoch 132/150\n",
      "27310/27310 [==============================] - 3s 104us/step - loss: 0.7127 - acc: 0.7172\n",
      "Epoch 133/150\n",
      "27310/27310 [==============================] - 3s 106us/step - loss: 0.7097 - acc: 0.7201 0s - loss: 0.7097 - acc: 0.\n",
      "Epoch 134/150\n",
      "27310/27310 [==============================] - 3s 105us/step - loss: 0.7102 - acc: 0.7175\n",
      "Epoch 135/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7104 - acc: 0.7198\n",
      "Epoch 136/150\n",
      "27310/27310 [==============================] - 3s 118us/step - loss: 0.7098 - acc: 0.7189\n",
      "Epoch 137/150\n",
      "27310/27310 [==============================] - 3s 118us/step - loss: 0.7091 - acc: 0.7180\n",
      "Epoch 138/150\n",
      "27310/27310 [==============================] - 3s 114us/step - loss: 0.7096 - acc: 0.7211\n",
      "Epoch 139/150\n",
      "27310/27310 [==============================] - 3s 108us/step - loss: 0.7100 - acc: 0.7180 0s - loss: 0.7082 - acc: \n",
      "Epoch 140/150\n",
      "27310/27310 [==============================] - 3s 108us/step - loss: 0.7089 - acc: 0.7211\n",
      "Epoch 141/150\n",
      "27310/27310 [==============================] - 3s 107us/step - loss: 0.7105 - acc: 0.7201\n",
      "Epoch 142/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7094 - acc: 0.7205\n",
      "Epoch 143/150\n",
      "27310/27310 [==============================] - 3s 115us/step - loss: 0.7091 - acc: 0.7212\n",
      "Epoch 144/150\n",
      "27310/27310 [==============================] - 3s 113us/step - loss: 0.7105 - acc: 0.7208\n",
      "Epoch 145/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7090 - acc: 0.7201\n",
      "Epoch 146/150\n",
      "27310/27310 [==============================] - 3s 109us/step - loss: 0.7069 - acc: 0.7197\n",
      "Epoch 147/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7090 - acc: 0.7205\n",
      "Epoch 148/150\n",
      "27310/27310 [==============================] - 3s 110us/step - loss: 0.7082 - acc: 0.7187\n",
      "Epoch 149/150\n",
      "27310/27310 [==============================] - 3s 116us/step - loss: 0.7083 - acc: 0.7209\n",
      "Epoch 150/150\n",
      "27310/27310 [==============================] - 3s 114us/step - loss: 0.7065 - acc: 0.7207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe1e144dd8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.fit(X, dummy_y, epochs=150, batch_size=32) #Attention aux paramètres, certains changement provoquent l'overfitting !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27310/27310 [==============================] - 2s 55us/step\n",
      "\n",
      "acc: 73.64%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, dummy_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B2' 'B2' 'B2' ... 'A1' 'A1' 'A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#predictions = model.predict(X)\n",
    "predictions = model.predict_classes(X)\n",
    "classes = encoder.inverse_transform(predictions)\n",
    "\n",
    "print(classes)\n",
    "# round predictions\n",
    "#for x in predictions :\n",
    "#    print(x)\n",
    "#print(dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(type(classes))\n",
    "sns.countplot(classes,label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

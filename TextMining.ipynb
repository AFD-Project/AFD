{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in d:\\python\\lib\\site-packages (4.8.2)\n",
      "Requirement already satisfied: jupyter-client in d:\\python\\lib\\site-packages (from ipykernel) (5.2.2)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in d:\\python\\lib\\site-packages (from ipykernel) (4.3.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in d:\\python\\lib\\site-packages (from ipykernel) (6.2.1)\n",
      "Requirement already satisfied: tornado>=4.0 in d:\\python\\lib\\site-packages (from ipykernel) (4.5.3)\n",
      "Requirement already satisfied: jupyter_core in d:\\python\\lib\\site-packages (from jupyter-client->ipykernel) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=13 in d:\\python\\lib\\site-packages (from jupyter-client->ipykernel) (16.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\python\\lib\\site-packages (from jupyter-client->ipykernel) (2.6.1)\n",
      "Requirement already satisfied: ipython_genutils in d:\\python\\lib\\site-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: six in d:\\python\\lib\\site-packages (from traitlets>=4.1.0->ipykernel) (1.11.0)\n",
      "Requirement already satisfied: decorator in d:\\python\\lib\\site-packages (from traitlets>=4.1.0->ipykernel) (4.2.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in d:\\python\\lib\\site-packages (from ipython>=4.0.0->ipykernel) (38.4.0)\n",
      "Requirement already satisfied: jedi>=0.10 in d:\\python\\lib\\site-packages (from ipython>=4.0.0->ipykernel) (0.11.1)\n",
      "Requirement already satisfied: pickleshare in d:\\python\\lib\\site-packages (from ipython>=4.0.0->ipykernel) (0.7.4)\n",
      "Requirement already satisfied: simplegeneric>0.8 in d:\\python\\lib\\site-packages (from ipython>=4.0.0->ipykernel) (0.8.1)\n",
      "Requirement already satisfied: prompt_toolkit<2.0.0,>=1.0.4 in d:\\python\\lib\\site-packages (from ipython>=4.0.0->ipykernel) (1.0.15)\n",
      "Requirement already satisfied: pygments in d:\\python\\lib\\site-packages (from ipython>=4.0.0->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: colorama in d:\\python\\lib\\site-packages (from ipython>=4.0.0->ipykernel) (0.3.9)\n",
      "Requirement already satisfied: parso==0.1.* in d:\\python\\lib\\site-packages (from jedi>=0.10->ipython>=4.0.0->ipykernel) (0.1.1)\n",
      "Requirement already satisfied: wcwidth in d:\\python\\lib\\site-packages (from prompt_toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel) (0.1.7)\n",
      "Requirement already satisfied: panda in d:\\python\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: requests in d:\\python\\lib\\site-packages (from panda) (2.18.4)\n",
      "Requirement already satisfied: setuptools in d:\\python\\lib\\site-packages (from panda) (38.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\python\\lib\\site-packages (from requests->panda) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in d:\\python\\lib\\site-packages (from requests->panda) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in d:\\python\\lib\\site-packages (from requests->panda) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python\\lib\\site-packages (from requests->panda) (2018.1.18)\n",
      "Requirement already satisfied: numpy in d:\\python\\lib\\site-packages (1.14.0)\n",
      "Requirement already satisfied: scipy in d:\\python\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: sklearn in d:\\python\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\python\\lib\\site-packages (from sklearn) (0.19.1)\n",
      "Requirement already satisfied: matplotlib in d:\\python\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.7.1 in d:\\python\\lib\\site-packages (from matplotlib) (1.14.0)\n",
      "Requirement already satisfied: six>=1.10 in d:\\python\\lib\\site-packages (from matplotlib) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\python\\lib\\site-packages (from matplotlib) (2.6.1)\n",
      "Requirement already satisfied: pytz in d:\\python\\lib\\site-packages (from matplotlib) (2017.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\python\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\python\\lib\\site-packages (from matplotlib) (2.2.0)\n",
      "Requirement already satisfied: nltk in d:\\python\\lib\\site-packages (3.2.5)\n",
      "Requirement already satisfied: six in d:\\python\\lib\\site-packages (from nltk) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipykernel\n",
    "!pip install panda \n",
    "!pip install numpy\n",
    "!pip install scipy\n",
    "!pip install sklearn\n",
    "!pip install matplotlib\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re \n",
    "import copy\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from __future__ import division\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kamel_000\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "    \n",
    "train = \"\" \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"DONNES/train_cap2018.csv\")\n",
    "df = df['fulltext']\n",
    "\n",
    "for line in saved_column:\n",
    "       train = train + line\n",
    "#print(train[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "esw = stopwords.words('english')\n",
    "esw.append('would')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pattern = re.compile(\"^\\w+$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize les mots et compte le total\n",
    "def get_text_counter(text):\n",
    "    tokens = WordPunctTokenizer().tokenize(PorterStemmer().stem(text))\n",
    "    tokens = list(map(lambda x: x.lower(), tokens))\n",
    "    tokens = [token for token in tokens if re.match(word_pattern,token) and token not in esw]\n",
    "    return collections.Counter(tokens),len(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui calcule la fréquence absolue et la fréquence relative des mots les plus utilisés\n",
    "def make_df(counter, size):\n",
    "    abs_freq = np.array([el[1] for el in counter])\n",
    "    rel_freq = abs_freq / size\n",
    "    index = [el[0] for el in counter]\n",
    "    df = pd.DataFrame(data=np.array([abs_freq, rel_freq]).T, index=index, columns=[\"Absolute Frequency\", \"Relative Frequency\"] )\n",
    "    df.index.name = \"Most common words\"\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Absolute Frequency</th>\n",
       "      <th>Relative Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most common words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>9524.0</td>\n",
       "      <td>0.010055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>6531.0</td>\n",
       "      <td>0.006895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>5887.0</td>\n",
       "      <td>0.006216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>5561.0</td>\n",
       "      <td>0.005871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>5522.0</td>\n",
       "      <td>0.005830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <td>5440.0</td>\n",
       "      <td>0.005744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>5359.0</td>\n",
       "      <td>0.005658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hi</th>\n",
       "      <td>5334.0</td>\n",
       "      <td>0.005632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>5272.0</td>\n",
       "      <td>0.005566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>4769.0</td>\n",
       "      <td>0.005035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Absolute Frequency  Relative Frequency\n",
       "Most common words                                        \n",
       "like                           9524.0            0.010055\n",
       "good                           6531.0            0.006895\n",
       "work                           5887.0            0.006216\n",
       "job                            5561.0            0.005871\n",
       "people                         5522.0            0.005830\n",
       "years                          5440.0            0.005744\n",
       "go                             5359.0            0.005658\n",
       "hi                             5334.0            0.005632\n",
       "one                            5272.0            0.005566\n",
       "name                           4769.0            0.005035"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calcule des mots les plus utilisés dans le fichier train, ça prend du temps donc ici échantillon des 10 mots les plus itlisés\n",
    "je_counter, je_size = get_text_counter(train)\n",
    "make_df(je_counter.most_common(10),je_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enregistre les 10 000 mots les plus utilisés dans un csv\n",
    "train_df = make_df(je_counter.most_common(10000), je_size)\n",
    "train_df.to_csv(\"DONNES/tokenize_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
